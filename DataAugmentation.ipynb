{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".png\"\n",
    "\n",
    "def append_extr(fnr):\n",
    "    return fnr+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=pd.read_csv(r\"C:\\Users\\M1048974\\Desktop\\object_detection\\train\\trainLabels.csv\",dtype=str,encoding = \"latin-1\")\n",
    "testdf=pd.read_csv(r\"C:\\Users\\M1048974\\Desktop\\object_detection\\object\\test_data.csv\",dtype=str,encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[\"id\"]=traindf[\"id\"].apply(append_ext)\n",
    "testdf[\"index\"] = testdf[\"index\"].apply(append_extr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255., validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.image_data_generator.ImageDataGenerator at 0x23620228278>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=r\"C:\\Users\\M1048974\\Desktop\\object_detection\\train\\train_data\\train_data_1\",\n",
    "x_col=\"id\",\n",
    "y_col=\"label\",\n",
    "subset=\"training\", # that means which subset we r using that will be validation or either training here we r using training\n",
    "batch_size=90, #size of the batches of data (default: 32).\n",
    "seed=42, # optional random seed for shuffling and transformations.\n",
    "shuffle=True, # whether to shuffle the data (default: True)\n",
    "class_mode=\"categorical\",   # One of \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\". \n",
    "                            # Determines the type of label arrays that are returned: - \"categorical\" \n",
    "                            # will be 2D one-hot encoded labels, \n",
    "target_size=(32,32)) #Tuple of integers (height, width), defaults to (256,256). \n",
    "                        # The dimensions to which all images found will be resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator at 0x23620c53940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=r\"C:\\Users\\M1048974\\Desktop\\object_detection\\train\\train_data\\train_data_1\",\n",
    "x_col=\"id\",\n",
    "y_col=\"label\",\n",
    "subset=\"validation\",\n",
    "batch_size=50,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator at 0x23620c53588>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1365 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=testdf,\n",
    "directory= r\"C:\\Users\\M1048974\\Desktop\\object_detection\\object\\test_data_folder\",\n",
    "x_col=\"index\",\n",
    "y_col=None,\n",
    "batch_size= 15,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "validate_filenames=False,\n",
    "target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator at 0x23620c537b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3),activation=\"relu\" ,padding='same',input_shape=(32,32,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = \"relu\" ,padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = \"relu\" ,padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizers=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 97s 194ms/step - loss: 1.6980 - accuracy: 0.3849 - val_loss: 1.3327 - val_accuracy: 0.5334\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 91s 181ms/step - loss: 1.2916 - accuracy: 0.5363 - val_loss: 1.2009 - val_accuracy: 0.5826\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 1.1117 - accuracy: 0.6060 - val_loss: 1.0204 - val_accuracy: 0.6442\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.9946 - accuracy: 0.6516 - val_loss: 0.8090 - val_accuracy: 0.7276\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 0.9236 - accuracy: 0.6790 - val_loss: 0.8339 - val_accuracy: 0.7076\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.8705 - accuracy: 0.6980 - val_loss: 0.7848 - val_accuracy: 0.7324\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 90s 181ms/step - loss: 0.8292 - accuracy: 0.7122 - val_loss: 0.7311 - val_accuracy: 0.7498\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 0.7987 - accuracy: 0.7257 - val_loss: 0.7505 - val_accuracy: 0.7590\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 90s 180ms/step - loss: 0.7790 - accuracy: 0.7336 - val_loss: 0.7137 - val_accuracy: 0.7722\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 91s 181ms/step - loss: 0.7672 - accuracy: 0.7384 - val_loss: 0.7334 - val_accuracy: 0.7652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23620c53860>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7333590403199196, 0.7652]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=valid_generator,steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 3s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "predictions = model.predict_generator(test_generator,steps=STEP_SIZE_TEST,verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=45,\n",
    "                    horizontal_flip=True,\n",
    "                    validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_data_aug.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=r\"C:\\Users\\M1048974\\Desktop\\object_detection\\train\\train_data\\train_data_1\",\n",
    "x_col=\"id\",\n",
    "y_col=\"label\",\n",
    "subset=\"training\", # that means which subset we r using that will be validation or either training here we r using training\n",
    "batch_size=90, #size of the batches of data (default: 32).\n",
    "shuffle=True, # whether to shuffle the data (default: True)\n",
    "class_mode=\"categorical\",   # One of \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\". \n",
    "target_size=(32,32))       # Determines the type of label arrays that are returned: - \"categorical\" \n",
    "                            # will be 2D one-hot encoded labels, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = ImageDataGenerator(rescale=1./255.,validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator_aug=train_data_aug.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=r\"C:\\Users\\M1048974\\Desktop\\object_detection\\train\\train_data\\train_data_1\",\n",
    "x_col=\"id\",\n",
    "y_col=\"label\",\n",
    "subset=\"validation\",\n",
    "batch_size=50,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug = Sequential()\n",
    "model_aug.add(Conv2D(32, (3, 3),activation=\"relu\" ,padding='same',input_shape=(32,32,3)))\n",
    "model_aug.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_aug.add(Dropout(0.20))\n",
    "\n",
    "model_aug.add(Conv2D(64, (3, 3), activation = \"relu\" ,padding='same'))\n",
    "model_aug.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_aug.add(Dropout(0.20))\n",
    "\n",
    "model_aug.add(Conv2D(128, (3, 3), activation = \"relu\" ,padding='same'))\n",
    "model_aug.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_aug.add(Dropout(0.20))\n",
    "\n",
    "model_aug.add(Flatten())\n",
    "model_aug.add(Dense(512))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(Dropout(0.4))\n",
    "\n",
    "model_aug.add(Dense(10, activation='softmax'))\n",
    "model_aug.compile(optimizers=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model_aug.load_weights('model_DA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,147,466\n",
      "Trainable params: 1,147,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN_AUG=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID_AUG=valid_generator_aug.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 101s 203ms/step - loss: 1.1954 - accuracy: 0.5889 - val_loss: 0.8697 - val_accuracy: 0.7188\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 94s 189ms/step - loss: 1.1609 - accuracy: 0.6014 - val_loss: 0.7769 - val_accuracy: 0.7410\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 1.1409 - accuracy: 0.6107 - val_loss: 0.8984 - val_accuracy: 0.7010\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 96s 192ms/step - loss: 1.1317 - accuracy: 0.6134 - val_loss: 0.8320 - val_accuracy: 0.7238\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 94s 189ms/step - loss: 1.1223 - accuracy: 0.6158 - val_loss: 0.8476 - val_accuracy: 0.7252\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 95s 189ms/step - loss: 1.1255 - accuracy: 0.6178 - val_loss: 0.8444 - val_accuracy: 0.7260\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 94s 187ms/step - loss: 1.1195 - accuracy: 0.6172 - val_loss: 0.8879 - val_accuracy: 0.7080\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 1.1237 - accuracy: 0.6196 - val_loss: 0.8368 - val_accuracy: 0.7328\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 94s 189ms/step - loss: 1.1139 - accuracy: 0.6235 - val_loss: 0.8360 - val_accuracy: 0.7196\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 1.1228 - accuracy: 0.6230 - val_loss: 0.8745 - val_accuracy: 0.6948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23620c53b38>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator_aug,\n",
    "                    validation_steps=STEP_SIZE_VALID_AUG,\n",
    "                    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_DA.h5')\n",
    "x = model.save('model_DA.h5')\n",
    "new_model = tf.keras.models.load_model('model_DA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(r'C:\\Users\\M1048974\\Desktop\\pic\\dog1.jpg')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1057284 , 0.10117178, 0.10969871, 0.09891579, 0.10011469,\n",
       "        0.09259758, 0.09211371, 0.09483733, 0.12124507, 0.08357693]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.resize((32,32),Image.ANTIALIAS)\n",
    "img_array = np.array(img)\n",
    "img_array = img_array.astype('float32')\n",
    "img_array /= 255\n",
    "img_array = np.expand_dims(img_array,axis=0)\n",
    "predict = new_model.predict(img_array)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is ---------------------->: Dog\n"
     ]
    }
   ],
   "source": [
    "labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Ship', 'Frog', 'Horse', 'Dog', 'Truck']\n",
    "index = (list(predict[0])).index(max((list(predict[0]))))\n",
    "print(\"prediction is ---------------------->:\",labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
